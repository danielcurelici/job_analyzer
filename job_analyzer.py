from openai import OpenAI
import streamlit as st
import os
import re
import requests
import pandas as pd
from bs4 import BeautifulSoup
from typing import List, Optional, Literal
from pydantic import BaseModel, Field, computed_field, field_validator
import instructor
from groq import Groq
from dotenv import load_dotenv
import json
from pydantic import ValidationError
import traceback


SENIORITY_MAPPING = {
    # INTERN
    "intern": "Intern",
    "internship": "Intern",
    "trainee": "Intern",
    "stagiar": "Intern",

    # JUNIOR
    "junior": "Junior",
    "jr": "Junior",
    "entry": "Junior",
    "entry-level": "Junior",
    "entry level": "Junior",
    "beginner": "Junior",
    "associate": "Junior",

    # MID
    "mid": "Mid",
    "mid-level": "Mid",
    "mid level": "Mid",
    "intermediate": "Mid",
    "regular": "Mid",

    # SENIOR
    "senior": "Senior",
    "sr": "Senior",
    "senior-level": "Senior",
    "expert": "Senior",
    "specialist": "Senior",

    # LEAD
    "lead": "Lead",
    "team lead": "Lead",
    "tech lead": "Lead",
    "principal": "Lead",

    # ARCHITECT
    "architect": "Architect",
    "solution architect": "Architect",
    "software architect": "Architect",
}

# ==============================================================================
# 1. SETUP & SECURITATE
# ==============================================================================
st.set_page_config(page_title="GenAI Headhunter", page_icon="üïµÔ∏è", layout="wide")

# √éncƒÉrcƒÉm variabilele din fi»ôierul .env
load_dotenv()

# √éncercƒÉm sƒÉ luƒÉm cheia din OS (local) sau din Streamlit Secrets (cloud)
groq_api_key = os.getenv("GROQ_API_KEY")
op_api_key = os.getenv("OPENROUTER_API_KEY")

# Fallback pentru Streamlit Cloud deployment
if not groq_api_key and "GROQ_API_KEY" in st.secrets:
    groq_api_key = st.secrets["GROQ_API_KEY"]

if not op_api_key and "OPENROUTER_API_KEY" in st.secrets:
    op_api_key = st.secrets["OPENROUTER_API_KEY"]


# Validare criticƒÉ: DacƒÉ nu avem cheie, oprim aplica»õia aici.
if not groq_api_key or not op_api_key:
    st.error("‚õî EROARE CRITICƒÇ: Lipse»ôte `GROQ_API_KEY` sau `OPENROUTER_API_KEY`.")
    st.info("Te rog creeazƒÉ un fi»ôier `.env` √Æn folderul proiectului »ôi adaugƒÉ: GROQ_API_KEY=cheia_ta_aici »ôi OPENROUTER_API_KEY=cheia_ta_aici")
    st.stop()

# Configurare Client Groq Global (pentru a nu-l reini»õializa constant)
groq_client = instructor.from_groq(Groq(api_key=groq_api_key), mode=instructor.Mode.JSON)
op_client = instructor.from_openai(OpenAI(api_key=op_api_key, base_url="https://openrouter.ai/api/v1"), mode=instructor.Mode.JSON)


# Sidebar Informativ (FƒÉrƒÉ input de date sensibile)
with st.sidebar:
    st.header("üïµÔ∏è GenAI Headhunter")
    st.success("‚úÖ API Key √ÆncƒÉrcat securizat")
    st.markdown("---")
    st.write("Acest tool demonstreazƒÉ:")
    st.write("‚Ä¢ Web Scraping (BS4)")
    st.write("‚Ä¢ Secure Env Variables")
    st.write("‚Ä¢ Structured Data (Pydantic)")


# ==============================================================================
# 2. DATA MODELS (PYDANTIC SCHEMAS)
# ==============================================================================
class Location(BaseModel):
    city: Optional[str] = Field(None, description="Ora»ôul")
    country: Optional[str] = Field(None, description="»öara")

class Red_flags(BaseModel):
    severity: Optional[Literal["low", "medium", "high"]] = Field(None, description="Nivelul de severitate al semnalului (ex: low, medium, high)")    
    category: Optional[Literal["toxicity", "vagueness", "unrealistic", "stress"]] = Field(None, description="Categoria semnalului de alarmƒÉ, Poate inseamnƒÉ cƒÉ anun»õul este neclar, ambiguu sau generic. Sau inseamnƒÉ cƒÉ cerin»õele sau oferta sunt nerealiste sau dispropor»õionate.")
  

class RawExtraction(BaseModel):
    role_title: str = Field(..., description="Titlul jobului standardizat")
    company_name: str = Field(..., description="Numele companiei")
    
    seniority: str = Field(..., description="Nivelul de experien»õƒÉ dedus")
    @field_validator("seniority", mode="before")
    @classmethod
    def normalize_seniority(cls, v):
        if not isinstance(v, str):
            return "Mid"

        key = v.strip().lower()
        return SENIORITY_MAPPING.get(key, "Mid")
    
    match_score: int = Field(..., ge=0, le=100, description="Scor 0-100: Calitatea descrierii jobului")
    tech_stack: List[str] = Field(..., description="ListƒÉ cu tehnologii specifice (ex: Python, AWS, React)")
    red_flags: List[Red_flags] = Field(..., description="Lista de semnale de alarmƒÉ (toxicitate, stres, vaguitate)")
    summary: str = Field(..., description="Un rezumat scurt al rolului (max 2 fraze) √Æn limba rom√¢nƒÉ")
    is_remote: bool = Field(False, description="True dacƒÉ jobul este remote sau hibrid")
    SalaryRange: Optional[str] = Field(
        default=None, 
        description='Interval salarial dacƒÉ este men»õionat (ex: "1000-5000 EUR")',
        json_schema_extra={"min_sal": 500, "max_sal": 5000, "currency": "EUR"},)
    location: Optional[Location] = Field(None, description="Loca»õia fizicƒÉ a jobului dacƒÉ este specificatƒÉ (ex: Bucure»ôti, Cluj, etc.)")  


    @computed_field
    @property
    def is_hybrid(self) -> bool:
        return self.is_remote and self.location is not None 

class FieldValidation(BaseModel):
    field: str
    status: Literal["ok", "warning", "error"]
    issues: List[str] = Field(default_factory=list)


class ValidationReport(BaseModel):
    fields: List[FieldValidation]
    overall_status: Literal["consistent", "minor_issues", "inconsistent"]
    confidence: int = Field(..., ge=0, le=100)

class StrategicAdvice(BaseModel):
    # 1Ô∏è‚É£ Potrivire cu pia»õa (RO)
    market_fit_summary: str = Field(..., description="Evaluare neutrƒÉ a anun»õului: c√¢t de bine se aliniazƒÉ cu pia»õa IT din Rom√¢nia »ôi unde poate fi √ÆmbunƒÉtƒÉ»õit.")
    market_improvements_for_hr: List[str] = Field(default_factory=list, description="Sugestii concrete pentru HR ca sƒÉ facƒÉ anun»õul mai competitiv/clar (ex: claritate rol, cerin»õe, beneficii, limbaj).")
    
    # 2Ô∏è‚É£ √éntrebƒÉri pentru formular de pre-screening (cƒÉtre candidat)
    pre_screening_form_knockout_questions: List[str] = Field(default_factory=list, description="√éntrebƒÉri eliminatorii/scurte pentru formular (eligibility, disponibilitate, cerin»õe must-have, salariu, remote/hybrid).")
    pre_screening_form_technical_questions: List[str] = Field(default_factory=list, description="√éntrebƒÉri tehnice pentru formular (rƒÉspuns scurt/multiple-choice) bazate pe cerin»õele din anun»õ.")
    pre_screening_form_behavioral_questions: List[str] = Field(default_factory=list, description="√éntrebƒÉri comportamentale pentru formular (rƒÉspuns scurt) relevante pentru rol.")
    
    # 3Ô∏è‚É£ Negociere salariu (cƒÉtre HR)
    salary_negotiation_tips_for_hr: List[str] = Field(default_factory=list, description="RecomandƒÉri pentru HR: cum sƒÉ pozi»õioneze oferta, ce sƒÉ clarifice, ce compromisuri sunt uzuale √Æn Rom√¢nia.")

# ==============================================================================
# 3. UTILS - SCRAPER (Colectare Date)
# ==============================================================================

def scrape_clean_job_text(url: str, max_chars: int = 3000) -> str:
    """
    DescarcƒÉ pagina »ôi returneazƒÉ un text curat, optimizat pentru contextul LLM.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            return f"Error: Status code {response.status_code}"
            
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # EliminƒÉm elementele inutile care consumƒÉ tokeni
        for junk in soup(["script", "style", "nav", "footer", "header", "aside", "iframe"]):
            junk.decompose()
            
        # Extragem textul »ôi eliminƒÉm spa»õiile multiple
        text = soup.get_text(separator=' ', strip=True)
        text = re.sub(r'\s+', ' ', text)
        
        return text[:max_chars] 
        
    except Exception as e:
        return f"Scraping Error: {str(e)}"

# ==============================================================================
# 4. AI SERVICE LAYER (Logica LLM)
# ==============================================================================

def extract_job_with_ai(text: str) -> RawExtraction:
    """
    Trimite textul curƒÉ»õat cƒÉtre Groq »ôi returneazƒÉ obiectul structurat.
    """
    try:
        return groq_client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        response_model=RawExtraction,
        response_format={"type": "json_object"},
        messages=[
            {
                "role": "system", 
                "content": (
                    "E»ôti un Recruiter Expert √Æn IT din Rom√¢nia care lucreazƒÉ √Æntr-o firmƒÉ de headhunting. "
                    "IdentificƒÉ tehnologiile »ôi poten»õialele probleme (red flags). "
                    "RƒÉspunde strict √Æn formatul cerut."
                )
            },
            {
                "role": "user", 
                "content": f"AnalizeazƒÉ acest job description:\n\n{text}"
            }
        ],
        max_retries=2,
        temperature=0,
    )
    except ValidationError as ve:
        st.error("ValidationError (RawExtraction)")
        st.json(ve.errors())
        raise

    except Exception:
        st.error("Eroare nea»ôteptatƒÉ (Extractor)")
        st.code(traceback.format_exc())
        raise
def validate_extraction_with_ai(original_text: str, extraction: RawExtraction) -> ValidationReport:
    """
    Agent 3: The Validator
    VerificƒÉ consisten»õa dintre textul original »ôi output-ul Extractorului.
    """

    try:
        return groq_client.chat.completions.create(
        model="moonshotai/kimi-k2-instruct-0905",
        response_model=ValidationReport,
        response_format={"type": "json_object"},
        temperature=0,
        max_retries=2,
        messages=[
            {
                "role": "system",
                "content": (
                    "E»ôti 'The Validator' √Æntr-un pipeline AI cu 3 agen»õi: Extractor, Validator, Counselor.\n\n"
                    "Rolul tƒÉu este sƒÉ verifici CONSISTEN»öA dintre textul original al jobului »ôi JSON-ul extras.\n"
                    "Pentru fiecare c√¢mp relevant (role_title, company_name, seniority, tech_stack, "
                    "is_remote, location, SalaryRange, summary, red_flags):\n"
                    "- MarcheazƒÉ status = 'ok' dacƒÉ este consistent.\n"
                    "- MarcheazƒÉ status = 'warning' dacƒÉ este par»õial ambiguu.\n"
                    "- MarcheazƒÉ status = 'error' dacƒÉ este gre»ôit sau inventat.\n\n"
                    "AdaugƒÉ issues DOAR dacƒÉ existƒÉ probleme reale.\n"
                    "Nu inventa informa»õii.\n"
                    "ReturneazƒÉ STRICT un ValidationReport valid JSON."
                )
            },
            {
                "role": "user",
                "content": (
                    "TEXT ORIGINAL:\n"
                    f"{original_text}\n\n"
                    "JSON EXTRAS:\n"
                    f"{extraction.model_dump_json(indent=2)}"
                )
            }
        ]
        
    )
    except ValidationError as ve:
        st.error("ValidationError (ValidationReport)")
        st.json(ve.errors())
        raise

    except Exception:
        st.error("Eroare nea»ôteptatƒÉ (Validator)")
        st.code(traceback.format_exc())
        raise

def strategic_advice_with_ai(extraction: RawExtraction) -> StrategicAdvice:
    try:
        return groq_client.chat.completions.create(
            model="groq/compound",  
            response_model=StrategicAdvice,
            response_format={"type": "json_object"},
            messages=[
                {
                    "role": "system",
                    "content": (
                        "E»ôti un Recruiter Expert √Æn IT din Rom√¢nia care lucreazƒÉ √Æntr-o firmƒÉ de headhunting. "
                        "Analizezi anun»õurile postate de HR cu scopul de a le √ÆmbunƒÉtƒÉ»õi. "
                        "ReturneazƒÉ STRICT JSON valid care respectƒÉ schema StrategicAdvice. "
                        "FƒÉrƒÉ text √Æn plus, fƒÉrƒÉ markdown."
                        "StructurƒÉ √Æn 3 categorii: "
                        "1) potrivire a anun»õului cu pia»õa din Rom√¢nia (»ôi √ÆmbunƒÉtƒÉ»õiri pentru HR), "
                        "2) √ÆntrebƒÉri pentru un formular de pre-screening completat de candidat (knockout + tehnic + comportamental), "
                        "3) recomandƒÉri pentru negociere salarialƒÉ adresate HR."
                    ),
                },
                {
                    "role": "user",
                    "content": (
                        "GenereazƒÉ analiza pe baza acestui JSON:\n\n"
                        f"{extraction.model_dump_json(indent=2)}"
                    ),
                },
            ],
            max_retries=2,
            temperature=0.7
        )

    except ValidationError as ve:
        st.error("ValidationError (StrategicAdvice)")
        st.json(ve.errors())  # aici vezi exact c√¢mpul care lipse»ôte / e gre»ôit
        raise

    except Exception as e:
        st.error("Eroare nea»ôteptatƒÉ: Counselor")
        st.code(traceback.format_exc())
        raise
    
# ==============================================================================
# 5. UI - APLICA»öIA STREAMLIT
# ==============================================================================

st.title("üïµÔ∏è GenAI Headhunter Assistant")
st.markdown("TransformƒÉ orice Job Description √Æntr-o analizƒÉ structuratƒÉ folosind AI.")

# Tab-uri
tab1, tab2 = st.tabs(["üöÄ AnalizƒÉ Job", "üìä Market Scan (Batch)"])

# --- TAB 1: ANALIZA UNUI SINGUR LINK ---
with tab1:
    st.subheader("AnalizeazƒÉ un Job URL")
    url_input = st.text_input("Introdu URL-ul:", placeholder="https://...")
    
    if st.button("AnalizeazƒÉ Job", key="btn_single"):
        if not url_input:
            st.warning("Te rugƒÉm introdu un URL.")
        else:
            with st.spinner("üï∑Ô∏è Scraping & ü§ñ AI Analysis..."):
                raw_text = scrape_clean_job_text(url_input)
            
            if "Error" in raw_text:
                st.error(raw_text)
            else:
                try:
                    data = extract_job_with_ai(raw_text)
                    # st.json(data)  # PRINT
                    validation = validate_extraction_with_ai(raw_text, data)
                    #st.json(validation)  # PRINT
                    
                    if validation.overall_status == "inconsistent":
                        st.warning("‚ö†Ô∏è Validator a detectat inconsisten»õe. Se √ÆncearcƒÉ re-extragerea automatƒÉ...")

                        # Retry extraction
                        data = extract_job_with_ai(raw_text)
                        validation = validate_extraction_with_ai(raw_text, data)

                        # DacƒÉ tot e inconsistent dupƒÉ retry
                        if validation.overall_status == "inconsistent":
                            st.error("‚ùå Extraction rƒÉm√¢ne inconsistentƒÉ dupƒÉ retry. Insight-urile pot fi afectate.")

                    elif validation.overall_status == "minor_issues":
                        st.info("‚ÑπÔ∏è Extraction are mici ambiguitƒÉ»õi.")


                    strategic_data = strategic_advice_with_ai(validation)
                    # st.json(strategic_data)  # PRINT

                    # -- DISPLAY --
                    st.divider()
                    col_h1, col_h2, col_h3 = st.columns([3, 2, 1])
                    with col_h1:
                        st.markdown(f"### {data.role_title}")
                        st.caption(f"Companie: **{data.company_name}** | Nivel: **{data.seniority}**")
                    with col_h2:
                        color = "normal" if validation.confidence > 70 else "inverse"
                        st.metric("Calitate AI", f"{validation.confidence}/100", delta_color=color)                    
                    with col_h3:
                        color = "normal" if data.match_score > 70 else "inverse"
                        st.metric("Calitate anunt", f"{data.match_score}/100", delta_color=color)


                
                    location_text = "N/A"

                    if data.location:
                        parts = []
                        if data.location.city:
                            parts.append(data.location.city)
                        if data.location.country:
                            parts.append(data.location.country)
                        if parts:
                            location_text = ", ".join(parts)

                    st.markdown("### üß© Overview")
                    c1, c2, c3 = st.columns([2, 1, 1])

                    with c1:
                        st.info(
                            f"""
                            **Mod lucru**  
                            - Remote: {'Da' if data.is_remote else 'Nu'}  
                            - Hybrid: {'Da' if data.is_hybrid else 'Nu'}  
                            - Loca»õie: {location_text}
                            """
                        )

                    with c2:
                        st.success(f"**Tehnologii**: {len(data.tech_stack)}")
                        st.info(f"**Interval salarial**: {data.SalaryRange or 'N/A'}")

                    with c3:
                        rf_count = len(data.red_flags)

                        if rf_count == 0:
                            st.success("**Red Flags**: 0")
                        else:
                            content = [f"### Red Flags: {rf_count}"]

                            for rf in data.red_flags:
                                if not rf.category:
                                    continue
                                category_label = rf.category.replace("_", " ").title()
                                severity_label = (rf.severity or "N/A").title()
                                content.append(f"‚Ä¢ **{category_label}** ‚Äî severitate: **{severity_label}**")

                            st.error("\n\n".join(content))

                    st.markdown("### üõ†Ô∏è Tech Stack")

                    if data.tech_stack:
                        st.markdown(
                            " ".join(f"`{tech}`" for tech in data.tech_stack)
                        )
                    else:
                        st.caption("N/A")

                    st.markdown(f"**üìù Rezumat job:** {data.summary}")
                    st.markdown(f"**üìù Aliniere cu piata din Romania:** {strategic_data.market_fit_summary}")

                    st.divider()
                    st.markdown("## üßæ Formular pre-screening (pentru candidat)")

                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.markdown("### üö´ Knockout")
                        qs = strategic_data.pre_screening_form_knockout_questions
                        if qs:
                            st.info("\n\n".join(f"**{i+1}.** {q}" for i, q in enumerate(qs)))
                        else:
                            st.caption("N/A")

                    with col2:
                        st.markdown("### üõ†Ô∏è Tehnic")
                        qs = strategic_data.pre_screening_form_technical_questions
                        if qs:
                            st.info("\n\n".join(f"**{i+1}.** {q}" for i, q in enumerate(qs)))
                        else:
                            st.caption("N/A")

                    with col3:
                        st.markdown("### üß† Comportamental")
                        qs = strategic_data.pre_screening_form_behavioral_questions
                        if qs:
                            st.info("\n\n".join(f"**{i+1}.** {q}" for i, q in enumerate(qs)))
                        else:
                            st.caption("N/A")

                    st.divider()
                    st.markdown("## üß© RecomandƒÉri pentru HR")

                    col_left, col_right = st.columns(2)

                    with col_left:
                        st.markdown("### üìà √émbunƒÉtƒÉ»õiri anun»õ")

                        imps = strategic_data.market_improvements_for_hr
                        if imps:
                            st.info("\n\n".join(f"‚Ä¢ {x}" for x in imps))
                        else:
                            st.caption("Nu existƒÉ sugestii.")

                    with col_right:
                        st.markdown("### üí∞ Negociere salarialƒÉ (HR)")
                        tips = strategic_data.salary_negotiation_tips_for_hr
                        if tips:
                            st.success("\n\n".join(f"‚Ä¢ {t}" for t in tips))
                        else:
                            st.caption("N/A")

                except Exception as e:
                    st.error(f"Eroare AI: {str(e)}")

# --- TAB 2: BATCH PROCESSING ---
with tab2:
    st.subheader("üìä ComparƒÉ mai multe joburi")
    urls_text = st.text_area("Paste URL-uri (unul pe linie):", height=200)
    
    if st.button("ScaneazƒÉ Pia»õa", key="btn_batch"):
        urls = [u.strip() for u in urls_text.split('\n') if u.strip()]
        
        if not urls:
            st.warning("Nu ai introdus link-uri.")
        else:
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, link in enumerate(urls):
                status_text.text(f"Analizez {i+1}/{len(urls)}...")
                text = scrape_clean_job_text(link)
                
                if "Error" not in text:
                    try:
                        res = extract_job_with_ai(text)
                        results.append({
                            "Role": res.role_title,
                            "Company": res.company_name,
                            "Seniority": res.seniority,
                            "Tech": res.tech_stack,
                            "Score": res.match_score
                        })
                    except:
                        pass # ContinuƒÉm chiar dacƒÉ unul crapƒÉ
                
                progress_bar.progress((i + 1) / len(urls))
            
            status_text.text("Gata!")
            
            if results:
                df = pd.DataFrame(results)
                st.dataframe(df)
                
                # Grafic simplu
                st.bar_chart(df['Seniority'].value_counts())

                print()