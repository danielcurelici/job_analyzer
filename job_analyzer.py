import streamlit as st
import os
import re
import requests
import pandas as pd
from bs4 import BeautifulSoup
from typing import List, Optional, Literal
from pydantic import BaseModel, Field, computed_field, field_validator
import instructor
from groq import Groq
from dotenv import load_dotenv
import json

SENIORITY_MAPPING = {
    # INTERN
    "intern": "Intern",
    "internship": "Intern",
    "trainee": "Intern",
    "stagiar": "Intern",

    # JUNIOR
    "junior": "Junior",
    "jr": "Junior",
    "entry": "Junior",
    "entry-level": "Junior",
    "entry level": "Junior",
    "beginner": "Junior",
    "associate": "Junior",

    # MID
    "mid": "Mid",
    "mid-level": "Mid",
    "mid level": "Mid",
    "intermediate": "Mid",
    "regular": "Mid",

    # SENIOR
    "senior": "Senior",
    "sr": "Senior",
    "senior-level": "Senior",
    "expert": "Senior",
    "specialist": "Senior",

    # LEAD
    "lead": "Lead",
    "team lead": "Lead",
    "tech lead": "Lead",
    "principal": "Lead",

    # ARCHITECT
    "architect": "Architect",
    "solution architect": "Architect",
    "software architect": "Architect",
}

# ==============================================================================
# 1. SETUP & SECURITATE
# ==============================================================================
st.set_page_config(page_title="GenAI Headhunter", page_icon="üïµÔ∏è", layout="wide")

# √éncƒÉrcƒÉm variabilele din fi»ôierul .env
load_dotenv()

# √éncercƒÉm sƒÉ luƒÉm cheia din OS (local) sau din Streamlit Secrets (cloud)
api_key = os.getenv("GROQ_API_KEY")

# Fallback pentru Streamlit Cloud deployment
if not api_key and "GROQ_API_KEY" in st.secrets:
    api_key = st.secrets["GROQ_API_KEY"]

# Validare criticƒÉ: DacƒÉ nu avem cheie, oprim aplica»õia aici.
if not api_key:
    st.error("‚õî EROARE CRITICƒÇ: Lipse»ôte `GROQ_API_KEY`.")
    st.info("Te rog creeazƒÉ un fi»ôier `.env` √Æn folderul proiectului »ôi adaugƒÉ: GROQ_API_KEY=cheia_ta_aici")
    st.stop()

# Configurare Client Groq Global (pentru a nu-l reini»õializa constant)
client = instructor.from_groq(Groq(api_key=api_key), mode=instructor.Mode.TOOLS)

# Sidebar Informativ (FƒÉrƒÉ input de date sensibile)
with st.sidebar:
    st.header("üïµÔ∏è GenAI Headhunter")
    st.success("‚úÖ API Key √ÆncƒÉrcat securizat")
    st.markdown("---")
    st.write("Acest tool demonstreazƒÉ:")
    st.write("‚Ä¢ Web Scraping (BS4)")
    st.write("‚Ä¢ Secure Env Variables")
    st.write("‚Ä¢ Structured Data (Pydantic)")


# ==============================================================================
# 2. DATA MODELS (PYDANTIC SCHEMAS)
# ==============================================================================
class Location(BaseModel):
    city: Optional[str] = Field(None, description="Ora»ôul")
    country: Optional[str] = Field(None, description="»öara")

class Red_flags(BaseModel):
    severity: Literal["low", "medium", "high"] = Field(None, description="Nivelul de severitate al semnalului (ex: low, medium, high)")    
    category: Literal["toxicity", "vagueness", "unrealistic", "stress"] = Field(None, description="Categoria semnalului de alarmƒÉ, Poate inseamnƒÉ cƒÉ anun»õul este neclar, ambiguu sau generic. Sau inseamnƒÉ cƒÉ cerin»õele sau oferta sunt nerealiste sau dispropor»õionate.")
  

class JobAnalysis(BaseModel):
    role_title: str = Field(..., description="Titlul jobului standardizat")
    company_name: str = Field(..., description="Numele companiei")
    
    seniority: str = Field(..., description="Nivelul de experien»õƒÉ dedus")
    @field_validator("seniority", mode="before")
    @classmethod
    def normalize_seniority(cls, v):
        if not isinstance(v, str):
            return "Mid"

        key = v.strip().lower()
        return SENIORITY_MAPPING.get(key, "Mid")
    
    match_score: int = Field(..., ge=0, le=100, description="Scor 0-100: Calitatea descrierii jobului")
    tech_stack: List[str] = Field(..., description="ListƒÉ cu tehnologii specifice (ex: Python, AWS, React)")
    red_flags: List[Red_flags] = Field(..., description="Lista de semnale de alarmƒÉ (toxicitate, stres, vaguitate)")
    summary: str = Field(..., description="Un rezumat scurt al rolului (max 2 fraze) √Æn limba rom√¢nƒÉ")
    is_remote: bool = Field(False, description="True dacƒÉ jobul este remote sau hibrid")
    SalaryRange: Optional[str] = Field(min_sal = 500, max_sal = 5000, currency = "EUR", description="Interval salarial dacƒÉ este men»õionat (ex: 1000-5000 EUR)")
    location: Optional[Location] = Field(None, description="Loca»õia fizicƒÉ a jobului dacƒÉ este specificatƒÉ (ex: Bucure»ôti, Cluj, etc.)")  


    @computed_field
    @property
    def is_hybrid(self) -> bool:
        return self.is_remote and self.location is not None 

# ==============================================================================
# 3. UTILS - SCRAPER (Colectare Date)
# ==============================================================================

def scrape_clean_job_text(url: str, max_chars: int = 3000) -> str:
    """
    DescarcƒÉ pagina »ôi returneazƒÉ un text curat, optimizat pentru contextul LLM.
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code != 200:
            return f"Error: Status code {response.status_code}"
            
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # EliminƒÉm elementele inutile care consumƒÉ tokeni
        for junk in soup(["script", "style", "nav", "footer", "header", "aside", "iframe"]):
            junk.decompose()
            
        # Extragem textul »ôi eliminƒÉm spa»õiile multiple
        text = soup.get_text(separator=' ', strip=True)
        text = re.sub(r'\s+', ' ', text)
        
        return text[:max_chars] 
        
    except Exception as e:
        return f"Scraping Error: {str(e)}"

# ==============================================================================
# 4. AI SERVICE LAYER (Logica LLM)
# ==============================================================================

def analyze_job_with_ai(text: str) -> JobAnalysis:
    """
    Trimite textul curƒÉ»õat cƒÉtre Groq »ôi returneazƒÉ obiectul structurat.
    """
    return client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        response_model=JobAnalysis,
        messages=[
            {
                "role": "system", 
                "content": (
                    "E»ôti un Recruiter Expert √Æn IT. AnalizeazƒÉ textul jobului cu obiectivitate. "
                    "IdentificƒÉ tehnologiile »ôi poten»õialele probleme (red flags). "
                    "RƒÉspunde strict √Æn formatul cerut."
                )
            },
            {
                "role": "user", 
                "content": f"AnalizeazƒÉ acest job description:\n\n{text}"
            }
        ],
        temperature=0.1,
    )

# ==============================================================================
# 5. UI - APLICA»öIA STREAMLIT
# ==============================================================================

st.title("üïµÔ∏è GenAI Headhunter Assistant")
st.markdown("TransformƒÉ orice Job Description √Æntr-o analizƒÉ structuratƒÉ folosind AI.")

# Tab-uri
tab1, tab2 = st.tabs(["üöÄ AnalizƒÉ Job", "üìä Market Scan (Batch)"])

# --- TAB 1: ANALIZA UNUI SINGUR LINK ---
with tab1:
    st.subheader("AnalizeazƒÉ un Job URL")
    url_input = st.text_input("Introdu URL-ul:", placeholder="https://...")
    
    if st.button("AnalizeazƒÉ Job", key="btn_single"):
        if not url_input:
            st.warning("Te rugƒÉm introdu un URL.")
        else:
            with st.spinner("üï∑Ô∏è Scraping & ü§ñ AI Analysis..."):
                raw_text = scrape_clean_job_text(url_input)
            
            if "Error" in raw_text:
                st.error(raw_text)
            else:
                try:
                    data = analyze_job_with_ai(raw_text)
                    st.json(data)  # PRINT
                    # -- DISPLAY --
                    st.divider()
                    col_h1, col_h2 = st.columns([3, 1])
                    with col_h1:
                        st.markdown(f"### {data.role_title}")
                        st.caption(f"Companie: **{data.company_name}** | Nivel: **{data.seniority}**")
                    with col_h2:
                        color = "normal" if data.match_score > 70 else "inverse"
                        st.metric("Quality Score", f"{data.match_score}/100", delta_color=color)

                    # Detalii
                    c1, c2, c3 = st.columns(3)

                    location_text = "N/A"

                    if data.location:
                        parts = []
                        if data.location.city:
                            parts.append(data.location.city)
                        if data.location.country:
                            parts.append(data.location.country)
                        if parts:
                            location_text = ", ".join(parts)

                    c1.info(
                    f"""
                    **Mod lucru:**  
                    - Remote: {'Da' if data.is_remote else 'Nu'}  
                    - Hybrid: {'Da, in locatia de mai jos' if data.is_hybrid else 'Nu'}  
                    - Loca»õie: {location_text}
                    """
)
                    c2.success(f"**Tehnologii:** {len(data.tech_stack)}")
                    c3.error(f"**Red Flags:** {len(data.red_flags)}")
                    c4, c5, c6 = st.columns(3)
                    c4.info(f"**Interval salarial:** {data.SalaryRange or 'N/A'}")


                    st.markdown(f"**üìù Rezumat:** {data.summary}")
                    st.markdown("#### üõ†Ô∏è Tech Stack")
                    st.write(", ".join([f"`{tech}`" for tech in data.tech_stack]))

                    if data.red_flags:
                        lines = []
                        for rf in data.red_flags:
                            if not rf.category:
                                continue
                            category_label = rf.category.replace("_", " ").title()
                            severity_label = (rf.severity or "N/A").title()
                            lines.append(f"- **{category_label}** ‚Äî severitate: **{severity_label}**")

                        if lines:
                            st.warning("\n".join(lines))
                        

                except Exception as e:
                    st.error(f"Eroare AI: {str(e)}")

# --- TAB 2: BATCH PROCESSING ---
with tab2:
    st.subheader("üìä ComparƒÉ mai multe joburi")
    urls_text = st.text_area("Paste URL-uri (unul pe linie):", height=200)
    
    if st.button("ScaneazƒÉ Pia»õa", key="btn_batch"):
        urls = [u.strip() for u in urls_text.split('\n') if u.strip()]
        
        if not urls:
            st.warning("Nu ai introdus link-uri.")
        else:
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, link in enumerate(urls):
                status_text.text(f"Analizez {i+1}/{len(urls)}...")
                text = scrape_clean_job_text(link)
                
                if "Error" not in text:
                    try:
                        res = analyze_job_with_ai(text)
                        results.append({
                            "Role": res.role_title,
                            "Company": res.company_name,
                            "Seniority": res.seniority,
                            "Tech": res.tech_stack,
                            "Score": res.match_score
                        })
                    except:
                        pass # ContinuƒÉm chiar dacƒÉ unul crapƒÉ
                
                progress_bar.progress((i + 1) / len(urls))
            
            status_text.text("Gata!")
            
            if results:
                df = pd.DataFrame(results)
                st.dataframe(df)
                
                # Grafic simplu
                st.bar_chart(df['Seniority'].value_counts())

                print()